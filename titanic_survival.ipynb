{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction with KNN\n",
    "\n",
    "This notebook predicts if a passenger on the Titanic survived or not using K-Nearest Neighbors (KNN) classifier.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Load and clean the dataset\n",
    "2. Engineer meaningful features\n",
    "3. Scale data for KNN\n",
    "4. Tune hyperparameters using GridSearchCV\n",
    "5. Evaluate model performance with accuracy, confusion matrix, and classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports & Setup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#machine learning components\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "#converter to scale of 0-1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#the actual model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "#visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and analize its structure, data types and missing values. \n",
    "As such parameter can affect the preditions.\n",
    "- No missing values in numerical columns (Age and Fare)\n",
    "- Non int values should be converted (gender)\n",
    "- Drop any irrelevant data (Name, Id, Cabin) \n",
    "- Create Bins to scale data (Age, Fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 2: Load Data and Initial Check missing values\n",
    "\n",
    "data = pd.read_csv(\"titanic.csv\")\n",
    "data.info()\n",
    "#get the amount of missing data\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning & Feature Engineering\n",
    "- Drop columns we don’t need (PassengerId, Name, Ticket, Cabin — nice for humans, useless for the model)\n",
    "- Fill missing values\n",
    "- Convert gender to numbers\n",
    "- Create new features to give the model more social/survival context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 3: Helper Functions\n",
    "\n",
    "# Data Cleaning & Feature Engineering (creating new columns)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], inplace=True)\n",
    "\n",
    "    df[\"Embarked\"].fillna(\"S\", inplace=True)\n",
    "    df.drop(columns=[\"Embarked\"], inplace=True)\n",
    "\n",
    "    fill_missing_ages(df)\n",
    "\n",
    "    # Convert Gender\n",
    "    df[\"Sex\"] = df[\"Sex\"].map({'male':1, \"female\":0})\n",
    "     \n",
    "        #We create a 'IsAlone, 'FareBin' and 'AgeBin' to determine the social patterns of survivers\n",
    "        #These can be use to predict how likely someone is to survive\n",
    "    \n",
    "    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"]\n",
    "    #is the passanger alone? if family size is 0, turn it to 0\n",
    "    df[\"IsAlone\"] = np.where(df[\"FamilySize\"] == 0, 1, 0)\n",
    "    #fill any missing fare data\n",
    "    df[\"Fare\"].fillna(df[\"Fare\"].median(), inplace=True)\n",
    "    df[\"FareBin\"] = pd.qcut(df[\"Fare\"], 4, labels=False)\n",
    "\n",
    "    df[\"AgeBin\"] = pd.cut(df[\"Age\"], bins=[0,12,20,40,60, np.inf],labels=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace missing ages with the median age for each passenger class (Pclass).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 3.5\n",
    "def fill_missing_ages(df):\n",
    "\n",
    "\n",
    "    #creating dictionary with the median age for each class\n",
    "    age_fill_map = {}\n",
    "    for pclass in df[\"Pclass\"].unique():\n",
    "        if pclass not in age_fill_map:\n",
    "            age_fill_map[pclass] = df[df[\"Pclass\"] == pclass][\"Age\"].median()\n",
    "    # “Go through every row in the DataFrame.\n",
    "    \"\"\"If Age is missing, \n",
    "        replace it with the median age for that rowss passenger class.\n",
    "        Otherwise, leave it as is.”\n",
    "    \"\"\"\n",
    "    df[\"Age\"] = df.apply(lambda row: age_fill_map[row[\"Pclass\"]] \n",
    "    if pd.isnull(row[\"Age\"]) else row[\"Age\"], axis=1)\n",
    "\n",
    "data = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply preprocessing to our dataset\n",
    "Split Features and Target\n",
    "X = features the model uses to guess  \n",
    "y = the correct answer (did they survive?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 4: Preprocess Data\n",
    "\n",
    "data = preprocess_data(data)\n",
    "\n",
    "# Create Features / Target Variables (Make Flashcards)\n",
    "X = data.drop(columns=[\"Survived\"])\n",
    "y = data[\"Survived\"] #correct answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- learning with 75% of the data, testing with 25%\n",
    "- Make sure everything’s on the same scale so distance-based models (like KNN) don’t freak out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 5: Train/Test Split & Scaling\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# ML Preprocessing\n",
    "\n",
    "scaler = MinMaxScaler() #makes all features comparable\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different:\n",
    "- number of neighbors\n",
    "- distance metrics\n",
    "- weighting methods\n",
    "Pick the combo with the best cross-validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 6: Hyperparemeter Tuning - knn \n",
    "def tune_model(X_train, y_train):\n",
    "    param_grid = {\n",
    "        \"n_neighbors\":range(1,21),\n",
    "        \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],\n",
    "        \"weights\": [\"uniform\", \"distance\"]\n",
    "    }\n",
    "\n",
    "    model = KNeighborsClassifier()\n",
    "    # find me the best settings with best results\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "best_model = tune_model(X_train, y_train)\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get predictions\n",
    "- Check accuracy\n",
    "- Build confusion matrix to see correct vs wrong guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 7: Predictions and Evaluate\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    #make predictions on  test set\n",
    "    prediction = model.predict(X_test)\n",
    "    #calculate the accuracy\n",
    "    accuracy = accuracy_score(y_test, prediction)\n",
    "    # return both and build a right vs wrong predictions\n",
    "    matrix = confusion_matrix(y_test, prediction)\n",
    "    return accuracy, matrix\n",
    "\n",
    "accuracy, matrix = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "print(f'Confusion Matrix: ')\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
